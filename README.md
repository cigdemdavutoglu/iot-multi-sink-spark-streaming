# IoT Telemetry Streaming with Spark Structured Streaming

Bu proje, IoT cihazlarÄ±ndan gelen sensÃ¶r verilerini gerÃ§ek zamanlÄ± olarak okuyup, belirli kurallara gÃ¶re **Ã¼Ã§ farklÄ± hedefe** yazan bir **Spark Structured Streaming** uygulamasÄ±dÄ±r.

## ğŸ“Œ Projenin AmacÄ±

GerÃ§ek zamanlÄ± veri iÅŸleme ile:
- `device` ID'sine gÃ¶re verileri filtrelemek,
- Filtrelenen verileri farklÄ± hedeflere yÃ¶nlendirmek:
  - ğŸ” **PostgreSQL** (device: `00:0f:00:70:91:0a`)
  - ğŸ **Hive (Parquet)** (device: `b8:27:eb:bf:9d:51`)
  - ğŸŒ€ **Delta Lake (HDFS)** (device: `1c:bf:ce:15:ec:4d`)

## ğŸ§± Proje YapÄ±sÄ±

- `read_from_csv.py`: Spark Structured Streaming uygulamasÄ±,
- `conf/`: Hive ve Spark konfigÃ¼rasyon dosyalarÄ±,
- `data-generator/output/`: Gelen CSV veri dosyalarÄ±,
- `checkpoint/`: Streaming checkpoint klasÃ¶rÃ¼,
- `requirements.txt`: Gerekli Python paketleri (varsa).

## âš™ï¸ KullanÄ±m

1. Projeyi klonlayÄ±n veya indirin:
```bash
git clone <repo-url>
cd <repo-folder>

## Gerekli Python paketlerini yÃ¼kleyin:
pip install -r requirements.txt
spark-submit read_from_csv.py



